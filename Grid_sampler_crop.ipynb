{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import glob\n",
    "import functools\n",
    "import tqdm\n",
    "import PIL\n",
    "import h5py\n",
    "from multiprocess import Pool\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn import datasets\n",
    "import time\n",
    "\n",
    "import torch\n",
    "# import torch.functional as F\n",
    "import torch.nn.functional as F\n",
    "\n",
    "eps = np.finfo(np.float64).eps\n",
    "\n",
    "plt.rcParams['figure.figsize'] = 10, 10\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load dataset and build tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "digits = datasets.load_digits()\n",
    "\n",
    "# Only use 1 image to make crop verification easier\n",
    "org_im = digits.images[0]\n",
    "\n",
    "# B, C, H, W = x.shape\n",
    "B = 4800\n",
    "H, W = 32, 32\n",
    "C = 1\n",
    "# Build the testing tensor\n",
    "x = torch.from_numpy(org_im).reshape(1, 1, 8, 8)\n",
    "x = F.interpolate(x, size=(H, W))\n",
    "x = x.repeat(B, C, 1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x11b8bfe80>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11b7a35f8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(x[0].squeeze().numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using F.grid_sample\n",
    "* https://discuss.pytorch.org/t/cropping-a-minibatch-of-images-each-image-a-bit-differently/12247/5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4800, 32, 32])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = x.squeeze()\n",
    "x.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "repeated grid size: torch.Size([4800, 4, 4, 2])\n",
      "rand_xoff size: torch.Size([4800, 4, 4])\n",
      "Sampled batch size: torch.Size([4800, 32, 4, 4])\n"
     ]
    }
   ],
   "source": [
    "def build_grid(source_size,target_size):\n",
    "    k = float(target_size)/float(source_size)\n",
    "    direct = torch.linspace(0, k, target_size).unsqueeze(0).repeat(target_size,1).unsqueeze(-1)\n",
    "    full = torch.cat([direct,direct.transpose(1,0)],dim=2).unsqueeze(0)\n",
    "    return full.type(torch.DoubleTensor) \n",
    "\n",
    "\n",
    "def random_crop_grid(x, grid):\n",
    "    delta = x.size(2)-grid.size(1)\n",
    "    grid = grid.repeat(x.size(0), 1, 1, 1)\n",
    "    print('repeated grid size: {}'.format(grid.size()))\n",
    "    \n",
    "    #Add random shifts by x and y [4800, 4, 4]\n",
    "    rand_xoff = torch.DoubleTensor(x.size(0)).random_(0, delta).unsqueeze(-1).unsqueeze(-1).expand(-1, grid.size(1), grid.size(2)) /x.size(2)\n",
    "    rand_yoff = torch.DoubleTensor(x.size(0)).random_(0, delta).unsqueeze(-1).unsqueeze(-1).expand(-1, grid.size(1), grid.size(2)) /x.size(2) \n",
    "    print('rand_xoff size: {}'.format(rand_xoff.size()))\n",
    "    \n",
    "    grid[:,:,:,0] = grid[:, :, :, 0] + rand_xoff\n",
    "    grid[:,:,:,1] = grid[:, :, :, 1] + rand_yoff\n",
    "    return grid\n",
    "\n",
    "\n",
    "#We want to crop a 4x4 image randomly for our batch\n",
    "#Building central crop of 4 pixel size \n",
    "grid_source = build_grid(x.size(2), 4)\n",
    "#Make radom shift for each batch\n",
    "grid_shifted = random_crop_grid(x, grid_source)\n",
    "#Sample using grid sample\n",
    "sampled_batch = F.grid_sample(x.unsqueeze(2), grid_shifted)\n",
    "\n",
    "print('Sampled batch size: {}'.format(sampled_batch.size()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
